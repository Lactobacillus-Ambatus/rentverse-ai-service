"""
ML model management for RentVerse AI Service.
"""

import logging
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional

import joblib
import numpy as np
import pandas as pd

from ..core.exceptions import ModelLoadError, PredictionError
from ..utils.preprocessor import ImprovedDataPreprocessor, validate_property_data

# Add compatibility import for existing pickled models
# This allows loading models that were pickled from the notebook's __main__ module
sys.modules['__main__'].ImprovedDataPreprocessor = ImprovedDataPreprocessor

logger = logging.getLogger(__name__)

# Constants
MODEL_NOT_LOADED_MSG = "Model not loaded"
DEFAULT_MODEL_DIR = Path(__file__).parent
DEFAULT_MODEL_FILENAME = "enhanced_deployment_pipeline.pkl"
FALLBACK_MODEL_FILENAME = "standard_deployment_pipeline.pkl"
LEGACY_ENHANCED_FILENAME = "enhanced_price_prediction_pipeline.pkl"
LEGACY_IMPROVED_FILENAME = "improved_price_prediction_pipeline.pkl"
MAX_BATCH_SIZE = 100


class PropertyPricePredictionModel:
    """
    Handles loading and inference for property price prediction models.
    Uses the deployment-ready pipeline with our utility preprocessor.
    """

    def __init__(self, model_dir: Optional[str] = None):
        self.pipeline_components = None
        self.preprocessor = None
        self.model = None
        self.scaler = None
        self.feature_names = None
        self.use_log_transform = False
        self.model_name = None
        self.performance_metrics = None
        self.is_loaded = False
        self.model_dir = model_dir or DEFAULT_MODEL_DIR

        self._load_pipeline()

    @property
    def model_version(self) -> str:
        """Get the model version."""
        return self.model_name or "Unknown"

    def _load_pipeline(self) -> None:
        """Load the pipeline from deployment pickle files."""
        try:
            # Try deployment pipelines first (preferred - dictionary format)
            model_candidates = [
                DEFAULT_MODEL_FILENAME,      # enhanced_deployment_pipeline.pkl
                FALLBACK_MODEL_FILENAME,     # standard_deployment_pipeline.pkl
                LEGACY_ENHANCED_FILENAME,    # enhanced_price_prediction_pipeline.pkl
                LEGACY_IMPROVED_FILENAME     # improved_price_prediction_pipeline.pkl
            ]

            model_path = None
            for candidate in model_candidates:
                candidate_path = os.path.join(self.model_dir, candidate)
                if os.path.exists(candidate_path):
                    model_path = candidate_path
                    logger.info(f"Found model: {candidate}")
                    break

            if not model_path:
                raise ModelLoadError(f"No model found in {self.model_dir}")

            # Load the pipeline components
            self.pipeline_components = joblib.load(model_path)
            logger.info(f"Loaded pipeline from {model_path}")

            # Handle both dictionary format (deployment) and legacy format
            if isinstance(self.pipeline_components, dict):
                # New deployment dictionary format
                required_keys = ['preprocessor', 'model', 'scaler', 'feature_names']
                missing_keys = [key for key in required_keys if key not in self.pipeline_components]
                if missing_keys:
                    raise ModelLoadError(f"Missing required keys in pipeline: {missing_keys}")

                self.preprocessor = self.pipeline_components['preprocessor']
                self.model = self.pipeline_components['model']
                self.scaler = self.pipeline_components['scaler']
                self.feature_names = self.pipeline_components['feature_names']
                self.use_log_transform = self.pipeline_components.get('use_log_transform', False)
                self.model_name = self.pipeline_components.get('model_name', 'Unknown')
                self.performance_metrics = self.pipeline_components.get('performance_metrics', {})
            else:
                # Legacy class-based format - extract components
                if hasattr(self.pipeline_components, 'preprocessor'):
                    self.preprocessor = self.pipeline_components.preprocessor
                    self.model = self.pipeline_components.model
                    self.scaler = self.pipeline_components.scaler
                    self.feature_names = self.pipeline_components.feature_names
                    self.use_log_transform = getattr(self.pipeline_components, 'use_log_transform', False)
                    self.model_name = getattr(self.pipeline_components, 'model_name', 'Unknown')
                    self.performance_metrics = getattr(self.pipeline_components, 'performance_metrics', {})
                else:
                    raise ModelLoadError("Invalid pipeline format")

            self.is_loaded = True
            logger.info(f"Pipeline loaded successfully:")
            logger.info(f"  - Model: {self.model_name}")
            logger.info(f"  - Features: {len(self.feature_names)} ({self.feature_names})")
            logger.info(f"  - Log transformation: {'enabled' if self.use_log_transform else 'disabled'}")
            logger.info(f"  - Performance: RÂ²={self.performance_metrics.get('test_r2', 'N/A')}")

        except Exception as e:
            logger.error(f"Failed to load pipeline: {str(e)}")
            raise ModelLoadError(f"Failed to load pipeline: {str(e)}")

    def predict(self, data: Dict[str, Any]) -> float:
        """
        Predict price for new data using the deployment pipeline.

        This method follows the deployment pipeline flow:
        1. Validate input data
        2. Convert input to DataFrame
        3. Apply preprocessing using ImprovedDataPreprocessor
        4. Extract and scale features
        5. Make prediction with optional log transformation

        Expected input format:
        - property_type: str (e.g., 'Condominium', 'Apartment')
        - bedrooms: int (e.g., 3)
        - bathrooms: int/float (e.g., 2)
        - area: int/float (e.g., 1200) - square feet
        - furnished: str (e.g., 'Yes', 'No', 'Partial')
        - location: str (e.g., 'KLCC, Kuala Lumpur')

        Returns:
        - predicted_price: float (in RM)
        """
        if not self.is_loaded or not self.pipeline_components:
            raise PredictionError(MODEL_NOT_LOADED_MSG)

        try:
            # Debug logging
            logger.debug(f"ML Model received data: {data}")
            logger.debug(f"Data type: {type(data)}")
            logger.debug(f"Data keys: {list(data.keys()) if isinstance(data, dict) else 'Not a dict'}")

            # Validate input data using our utility function
            validated_data = validate_property_data(data)
            logger.debug(f"Validated input data: {validated_data}")

            # Convert to DataFrame
            if isinstance(validated_data, dict):
                df = pd.DataFrame([validated_data])
            else:
                df = validated_data.copy()

            # Apply preprocessing using the loaded preprocessor
            # Set verbose=False for API usage to reduce logging
            original_verbose = getattr(self.preprocessor, 'verbose', True)
            if hasattr(self.preprocessor, 'verbose'):
                self.preprocessor.verbose = False

            try:
                processed_df = self.preprocessor.transform(df)
            finally:
                # Restore original verbose setting
                if hasattr(self.preprocessor, 'verbose'):
                    self.preprocessor.verbose = original_verbose

            logger.debug(f"Processed data shape: {processed_df.shape}")

            # Extract features used for training (excluding price if present)
            available_features = [col for col in self.feature_names if col in processed_df.columns]
            if len(available_features) != len(self.feature_names):
                missing_features = set(self.feature_names) - set(available_features)
                logger.warning(f"Missing features: {missing_features}")

            feature_df = processed_df[available_features]
            logger.debug(f"Feature extraction: {len(available_features)} features selected")

            # Scale features using the trained scaler
            scaled_features = self.scaler.transform(feature_df)
            logger.debug(f"Features scaled: {scaled_features.shape}")

            # Make prediction with optional log transformation
            if self.use_log_transform:
                # Enhanced pipeline with log transformation
                prediction_log = self.model.predict(scaled_features)
                prediction = np.expm1(prediction_log)  # Transform back from log scale
                logger.debug(f"Log prediction: {prediction_log[0]:.4f} -> Final: RM {prediction[0]:,.0f}")
            else:
                # Standard pipeline (no log transformation)
                prediction = self.model.predict(scaled_features)
                logger.debug(f"Direct prediction: RM {prediction[0]:,.0f}")

            result = float(prediction[0])
            logger.info(f"Prediction completed: RM {result:,.0f}")

            # Validate prediction is reasonable (RM 500 - RM 50,000)
            if not (500 <= result <= 50000):
                logger.warning(f"Prediction outside reasonable range: RM {result:,.0f}")

            return result

        except Exception as e:
            logger.error(f"Prediction failed: {str(e)}")
            raise PredictionError(f"Prediction failed: {str(e)}")

    def predict_single(self, property_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Predict price for a single property and return detailed results.

        Args:
            property_data: Dictionary containing property features

        Returns:
            Dictionary with prediction results including confidence metrics
        """
        if not self.is_loaded or not self.pipeline_components:
            raise PredictionError(MODEL_NOT_LOADED_MSG)

        try:
            # Get the core prediction
            predicted_price = self.predict(property_data)

            # Calculate confidence score based on actual model performance
            if self.performance_metrics:
                base_confidence = self.performance_metrics.get('cv_mean', 0.7)
                test_r2 = self.performance_metrics.get('test_r2', 0.7)

                # Adjust confidence based on model quality
                if test_r2 >= 0.8:
                    confidence_adjustment = np.random.normal(0.05, 0.02)
                elif test_r2 >= 0.6:
                    confidence_adjustment = np.random.normal(0.02, 0.03)
                else:
                    confidence_adjustment = np.random.normal(-0.05, 0.05)

                confidence_score = min(0.95, max(0.6, base_confidence + confidence_adjustment))
            else:
                confidence_score = np.random.uniform(0.75, 0.90)

            # Calculate price range based on model performance
            if self.performance_metrics:
                test_r2 = self.performance_metrics.get('test_r2', 0.7)
                uncertainty_factor = 1 - test_r2
                range_factor = 0.10 + (uncertainty_factor * 0.15) # 10-25% range
            else:
                range_factor = 0.15  # Default 15% range

            return {
                'predicted_price': float(predicted_price),
                'confidence_score': float(confidence_score),
                'price_range': {
                    'min': float(predicted_price * (1 - range_factor)),
                    'max': float(predicted_price * (1 + range_factor))
                },
                'currency': 'RM',
                'status': 'success',
                'model_version': self.model_name,
                'features_used': self.feature_names,
                'timestamp': datetime.now().isoformat()
            }

        except Exception as e:
            logger.error(f"Single prediction failed: {str(e)}")
            raise PredictionError(f"Single prediction failed: {str(e)}")

    def predict_batch(self, properties_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Predict prices for multiple properties using the complete pipeline.

        Args:
            properties_data: List of property feature dictionaries

        Returns:
            List of prediction result dictionaries
        """
        if not self.is_loaded or not self.pipeline_components:
            raise PredictionError(MODEL_NOT_LOADED_MSG)

        if len(properties_data) > MAX_BATCH_SIZE:
            raise PredictionError(f"Batch size {len(properties_data)} exceeds maximum {MAX_BATCH_SIZE}")

        results = []

        for i, prop_data in enumerate(properties_data):
            try:
                result = self.predict_single(prop_data)
                result['batch_index'] = i
                results.append(result)
            except Exception as e:
                logger.error(f"Failed to predict for property {i}: {str(e)}")
                results.append({
                    'batch_index': i,
                    'error': str(e),
                    'status': 'error',
                    'timestamp': datetime.now().isoformat()
                })

        return results

    def get_model_info(self) -> Dict[str, Any]:
        """Get detailed model information from the pipeline components."""
        if not self.is_loaded or not self.pipeline_components:
            raise PredictionError(MODEL_NOT_LOADED_MSG)

        # Extract feature importance if available
        feature_importance = None
        if hasattr(self.model, 'feature_importances_'):
            feature_importance = dict(zip(self.feature_names, self.model.feature_importances_.tolist()))

        return {
            'model_version': self.model_name,
            'created_at': datetime.now().isoformat(),
            'feature_columns': self.feature_names,
            'supported_property_types': ['Apartment', 'Condominium', 'Service Residence', 'Townhouse'],
            'supported_furnished_types': ['Yes', 'No', 'Partial', 'Fully Furnished', 'Partially Furnished', 'Unfurnished'],
            'is_loaded': self.is_loaded,
            'max_batch_size': MAX_BATCH_SIZE,
            'use_log_transform': self.use_log_transform,
            'performance_metrics': self.performance_metrics,
            'feature_importance': feature_importance,
            'pipeline_components_keys': list(self.pipeline_components.keys()),
            'expected_input_format': {
                'property_type': 'str (e.g., "Condominium")',
                'bedrooms': 'int (e.g., 3)',
                'bathrooms': 'int/float (e.g., 2)',
                'area': 'int/float (e.g., 1200) - square feet',
                'furnished': 'str (e.g., "Yes", "No", "Partial")',
                'location': 'str (e.g., "KLCC, Kuala Lumpur")'
            }
        }

    def health_check(self) -> Dict[str, Any]:
        """Perform a health check on the model with realistic Malaysian property data."""
        try:
            if not self.is_loaded or not self.pipeline_components:
                return {
                    'status': 'unhealthy',
                    'message': 'Pipeline not loaded',
                    'timestamp': datetime.now().isoformat()
                }

            # Test prediction with realistic Malaysian property data matching notebook format
            test_data = {
                'property_type': 'Condominium',
                'bedrooms': 3,
                'bathrooms': 2,
                'area': 1200,  # sqft
                'furnished': 'Yes',
                'location': 'KLCC, Kuala Lumpur'
            }

            predicted_price = self.predict(test_data)

            # Validate prediction is reasonable for Malaysian market (RM 500 - RM 15,000)
            if 500 <= predicted_price <= 15000:
                status = 'healthy'
                message = 'Model is working correctly'
            elif predicted_price < 500:
                status = 'warning'
                message = 'Model prediction seems low but functional'
            elif predicted_price <= 50000:
                status = 'healthy'
                message = 'Model prediction in high-end range but reasonable'
            else:
                status = 'warning'
                message = 'Model prediction seems very high but functional'

            return {
                'status': status,
                'message': message,
                'test_prediction': float(predicted_price),
                'test_data': test_data,
                'model_info': {
                    'model_name': self.model_name,
                    'use_log_transform': self.use_log_transform,
                    'feature_count': len(self.feature_names)
                },
                'timestamp': datetime.now().isoformat()
            }

        except Exception as e:
            logger.error(f"Health check failed: {str(e)}")
            return {
                'status': 'unhealthy',
                'message': f'Health check failed: {str(e)}',
                'timestamp': datetime.now().isoformat()
            }

    def classify_listing_approval(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Classify if a listing should be approved based on price prediction and other factors.
        
        Args:
            data: Dictionary containing property details and asking price
        
        Returns:
            Dictionary with approval classification results
        """
        if not self.is_loaded or not self.pipeline_components:
            raise PredictionError(MODEL_NOT_LOADED_MSG)

        try:
            # Get predicted price first
            predicted_price = self.predict(data)
            asking_price = data.get('asking_price', 0)
            
            if asking_price <= 0:
                raise ValueError("Asking price must be provided and positive")
            
            # Calculate price deviation
            price_deviation = ((asking_price - predicted_price) / predicted_price) * 100
            
            # Classification logic based on price deviation and other factors
            approval_reasons = []
            recommendations = []
            
            # Price-based classification
            if abs(price_deviation) <= 15:  # Within 15% of predicted price
                price_status = "acceptable"
                approval_reasons.append("Price within acceptable range")
            elif price_deviation > 15:
                price_status = "overpriced"
                recommendations.append(f"Consider reducing price by {price_deviation - 15:.1f}% for better market fit")
            else:  # price_deviation < -15
                price_status = "underpriced"
                approval_reasons.append("Competitively priced")
                recommendations.append("Price is very competitive, consider slight increase if demand is high")
            
            # Property quality factors
            bedrooms = data.get('bedrooms', 0)
            bathrooms = data.get('bathrooms', 0)
            area = data.get('area', 0)
            
            # Check property specifications
            if bedrooms >= 1 and bathrooms >= 1 and area >= 300:
                approval_reasons.append("Adequate property specifications")
            else:
                recommendations.append("Verify property specifications meet minimum standards")
            
            # Location assessment (basic)
            location = data.get('location', '').lower()
            premium_areas = ['klcc', 'mont kiara', 'bangsar', 'damansara', 'shah alam', 'petaling jaya']
            if any(area in location for area in premium_areas):
                approval_reasons.append("Good location")
            
            # Facilities assessment
            facilities = data.get('facilities', [])
            if facilities and len(facilities) >= 2:
                approval_reasons.append("Adequate facilities")
            elif not facilities:
                recommendations.append("Consider highlighting available facilities")
            
            # Final approval decision
            if price_status == "acceptable" and len(approval_reasons) >= 2:
                approval_status = "approved"
                confidence_score = min(0.9, 0.6 + (len(approval_reasons) * 0.1))
            elif price_status == "overpriced" and price_deviation > 30:
                approval_status = "rejected"
                confidence_score = min(0.85, 0.5 + (abs(price_deviation) / 100))
                approval_reasons = ["Price significantly above market rate"]
                recommendations.append("Adjust pricing to market standards")
            else:
                approval_status = "needs_review"
                confidence_score = 0.7
                if not approval_reasons:
                    approval_reasons.append("Requires manual review")
                recommendations.append("Manual review recommended for final approval")
            
            return {
                "approval_status": approval_status,
                "confidence_score": round(confidence_score, 2),
                "predicted_price": round(predicted_price, 2),
                "asking_price": asking_price,
                "price_deviation": round(price_deviation, 1),
                "approval_reasons": approval_reasons,
                "recommendations": recommendations if recommendations else None,
                "status": "success"
            }
            
        except Exception as e:
            logger.error(f"Error in listing approval classification: {str(e)}")
            raise PredictionError(f"Failed to classify listing approval: {str(e)}")


# Global model instance - will be initialized on first use
ml_model: Optional[PropertyPricePredictionModel] = None


def get_ml_model() -> PropertyPricePredictionModel:
    """Get the global ML model instance, creating it if necessary."""
    global ml_model
    if ml_model is None:
        ml_model = PropertyPricePredictionModel()
    return ml_model


def reload_ml_model(model_dir: Optional[str] = None) -> PropertyPricePredictionModel:
    """Reload the model with a new directory."""
    global ml_model
    ml_model = PropertyPricePredictionModel(model_dir)
    return ml_model


# Legacy compatibility functions
def get_model() -> PropertyPricePredictionModel:
    """Legacy compatibility function."""
    return get_ml_model()


def reload_model(model_path: Optional[str] = None) -> PropertyPricePredictionModel:
    """Legacy compatibility function."""
    return reload_ml_model(model_path)
